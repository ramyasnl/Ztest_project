{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Heart_Neural_network.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM0Wg9RIu97iPTCaPtPyQoN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramyasnl/test_project/blob/applebranch/Copy_of_Heart_Neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVAqeb3GROmD"
      },
      "source": [
        "# Import our dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "JlVHqg3gSEAZ",
        "outputId": "eb9adbf2-2b7c-4c01-fc01-2e08706f3ac6"
      },
      "source": [
        "heart_failure_df = pd.read_csv('https://ramyasnl-finalproject.s3.us-east-2.amazonaws.com/heart_failure_clinical_records_dataset.csv')\n",
        "heart_failure_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>anaemia</th>\n",
              "      <th>creatinine_phosphokinase</th>\n",
              "      <th>diabetes</th>\n",
              "      <th>ejection_fraction</th>\n",
              "      <th>high_blood_pressure</th>\n",
              "      <th>platelets</th>\n",
              "      <th>serum_creatinine</th>\n",
              "      <th>serum_sodium</th>\n",
              "      <th>sex</th>\n",
              "      <th>smoking</th>\n",
              "      <th>time</th>\n",
              "      <th>DEATH_EVENT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>75.0</td>\n",
              "      <td>0</td>\n",
              "      <td>582</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>265000.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>130</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>55.0</td>\n",
              "      <td>0</td>\n",
              "      <td>7861</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>263358.03</td>\n",
              "      <td>1.1</td>\n",
              "      <td>136</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65.0</td>\n",
              "      <td>0</td>\n",
              "      <td>146</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>162000.00</td>\n",
              "      <td>1.3</td>\n",
              "      <td>129</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>50.0</td>\n",
              "      <td>1</td>\n",
              "      <td>111</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>210000.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>137</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>65.0</td>\n",
              "      <td>1</td>\n",
              "      <td>160</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>327000.00</td>\n",
              "      <td>2.7</td>\n",
              "      <td>116</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    age  anaemia  creatinine_phosphokinase  ...  smoking  time  DEATH_EVENT\n",
              "0  75.0        0                       582  ...        0     4            1\n",
              "1  55.0        0                      7861  ...        0     6            1\n",
              "2  65.0        0                       146  ...        1     7            1\n",
              "3  50.0        1                       111  ...        0     7            1\n",
              "4  65.0        1                       160  ...        0     8            1\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "MdGxiqnjVioz",
        "outputId": "51f8c09c-f3ad-474f-c7aa-a3a9372afebe"
      },
      "source": [
        "heart_df = pd.read_csv('https://ramyasnl-finalproject.s3.us-east-2.amazonaws.com/heart.csv')\n",
        "heart_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trtbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalachh</th>\n",
              "      <th>exng</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slp</th>\n",
              "      <th>caa</th>\n",
              "      <th>thall</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>145</td>\n",
              "      <td>233</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>250</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>130</td>\n",
              "      <td>204</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>120</td>\n",
              "      <td>236</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>178</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>354</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>163</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  sex  cp  trtbps  chol  fbs  ...  exng  oldpeak  slp  caa  thall  output\n",
              "0   63    1   3     145   233    1  ...     0      2.3    0    0      1       1\n",
              "1   37    1   2     130   250    0  ...     0      3.5    0    0      2       1\n",
              "2   41    0   1     130   204    0  ...     0      1.4    2    0      2       1\n",
              "3   56    1   1     120   236    0  ...     0      0.8    2    0      2       1\n",
              "4   57    0   0     120   354    0  ...     1      0.6    2    0      2       1\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4_mTMs6WXFA",
        "outputId": "bb6e82d0-b7a3-4e62-add8-6824337a56ea"
      },
      "source": [
        "heart_df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 303 entries, 0 to 302\n",
            "Data columns (total 14 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   age       303 non-null    int64  \n",
            " 1   sex       303 non-null    int64  \n",
            " 2   cp        303 non-null    int64  \n",
            " 3   trtbps    303 non-null    int64  \n",
            " 4   chol      303 non-null    int64  \n",
            " 5   fbs       303 non-null    int64  \n",
            " 6   restecg   303 non-null    int64  \n",
            " 7   thalachh  303 non-null    int64  \n",
            " 8   exng      303 non-null    int64  \n",
            " 9   oldpeak   303 non-null    float64\n",
            " 10  slp       303 non-null    int64  \n",
            " 11  caa       303 non-null    int64  \n",
            " 12  thall     303 non-null    int64  \n",
            " 13  output    303 non-null    int64  \n",
            "dtypes: float64(1), int64(13)\n",
            "memory usage: 33.3 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NW6WTvKDWeAv"
      },
      "source": [
        "Attribute Information:\n",
        "From :https://archive.ics.uci.edu/ml/datasets/heart+disease\n",
        "0.age: age in years\n",
        "1.sex: sex (1 = male; 0 = female)\n",
        "2.cp: chest pain type\n",
        "-- Value 1: typical angina\n",
        "-- Value 2: atypical angina\n",
        "-- Value 3: non-anginal pain\n",
        "-- Value 4: asymptomatic\n",
        "3.trtbps:(restbps: )resting blood pressure (in mm Hg on admission to the hospital)\n",
        "4.chol: serum cholestoral in mg/dl\n",
        "5.fbs: (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\n",
        "6.restecg: resting electrocardiographic results\n",
        "-- Value 0: normal\n",
        "-- Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\n",
        "-- Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n",
        "7.thalach: maximum heart rate achieved\n",
        "8.exang: exercise induced angina (1 = yes; 0 = no)\n",
        "9.oldpeak = ST depression induced by exercise relative to rest\n",
        "10.slp:( slope:) the slope of the peak exercise ST segment\n",
        "-- Value 1: upsloping\n",
        "-- Value 2: flat\n",
        "-- Value 3: downsloping\n",
        "11.caa:ca: number of major vessels (0-3) colored by flourosopy\n",
        "12.thall:(thal:) 3 = normal; 6 = fixed defect; 7 = reversable defect\n",
        "13.output :num: diagnosis of heart disease (angiographic disease status)\n",
        "-- Value 0: < 50% diameter narrowing\n",
        "-- Value 1: > 50% diameter narrowing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "zL1pMCFtWmBo",
        "outputId": "ad1c8059-3f6c-44f8-9386-68237bad8a15"
      },
      "source": [
        "heart_df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trtbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalachh</th>\n",
              "      <th>exng</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slp</th>\n",
              "      <th>caa</th>\n",
              "      <th>thall</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>54.366337</td>\n",
              "      <td>0.683168</td>\n",
              "      <td>0.966997</td>\n",
              "      <td>131.623762</td>\n",
              "      <td>246.264026</td>\n",
              "      <td>0.148515</td>\n",
              "      <td>0.528053</td>\n",
              "      <td>149.646865</td>\n",
              "      <td>0.326733</td>\n",
              "      <td>1.039604</td>\n",
              "      <td>1.399340</td>\n",
              "      <td>0.729373</td>\n",
              "      <td>2.313531</td>\n",
              "      <td>0.544554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>9.082101</td>\n",
              "      <td>0.466011</td>\n",
              "      <td>1.032052</td>\n",
              "      <td>17.538143</td>\n",
              "      <td>51.830751</td>\n",
              "      <td>0.356198</td>\n",
              "      <td>0.525860</td>\n",
              "      <td>22.905161</td>\n",
              "      <td>0.469794</td>\n",
              "      <td>1.161075</td>\n",
              "      <td>0.616226</td>\n",
              "      <td>1.022606</td>\n",
              "      <td>0.612277</td>\n",
              "      <td>0.498835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>29.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>126.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>47.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>211.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>133.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>55.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>240.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>153.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>61.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>274.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>166.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>77.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>564.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>202.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.200000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              age         sex          cp  ...         caa       thall      output\n",
              "count  303.000000  303.000000  303.000000  ...  303.000000  303.000000  303.000000\n",
              "mean    54.366337    0.683168    0.966997  ...    0.729373    2.313531    0.544554\n",
              "std      9.082101    0.466011    1.032052  ...    1.022606    0.612277    0.498835\n",
              "min     29.000000    0.000000    0.000000  ...    0.000000    0.000000    0.000000\n",
              "25%     47.500000    0.000000    0.000000  ...    0.000000    2.000000    0.000000\n",
              "50%     55.000000    1.000000    1.000000  ...    0.000000    2.000000    1.000000\n",
              "75%     61.000000    1.000000    2.000000  ...    1.000000    3.000000    1.000000\n",
              "max     77.000000    1.000000    3.000000  ...    4.000000    3.000000    1.000000\n",
              "\n",
              "[8 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cduqOVYzWutP",
        "outputId": "c8095b7a-8505-490a-8c98-60a2553cd6f5"
      },
      "source": [
        "#Check the data for imbalances\n",
        "heart_df.output.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    165\n",
              "0    138\n",
              "Name: output, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KPu96YoW0LP",
        "outputId": "ad087381-260f-4d4f-e814-844f24e50e75"
      },
      "source": [
        "#Check the maximum correlation of the heart_df.output with other variables\n",
        "heart_df.corr().abs()['output'].sort_values(ascending = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "output      1.000000\n",
              "exng        0.436757\n",
              "cp          0.433798\n",
              "oldpeak     0.430696\n",
              "thalachh    0.421741\n",
              "caa         0.391724\n",
              "slp         0.345877\n",
              "thall       0.344029\n",
              "sex         0.280937\n",
              "age         0.225439\n",
              "trtbps      0.144931\n",
              "restecg     0.137230\n",
              "chol        0.085239\n",
              "fbs         0.028046\n",
              "Name: output, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dbSr3tZW5kH"
      },
      "source": [
        "# Split our preprocessed and checked  data into our features and target arrays\n",
        "y = heart_df['output'].values\n",
        "X = heart_df.drop(['output'],1).values\n",
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=86)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEdYWz_yW9SA"
      },
      "source": [
        "# Create a StandardScaler instances\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkU2_8ENXBMZ",
        "outputId": "7845816e-086a-4e0b-a6ef-bd573df850d1"
      },
      "source": [
        "len(X_train_scaled[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNfl1BVLXNpg"
      },
      "source": [
        "# ** Compile, Train and Evaluate the Model **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HsZcmx4XYZ4",
        "outputId": "77a943b2-404b-4e98-a8d3-793d97d3d921"
      },
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "number_input_features = len(X_train_scaled [0])\n",
        "hidden_nodes_layer1 =  40\n",
        "hidden_nodes_layer2 = 26\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(\n",
        "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
        ")\n",
        "\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 40)                560       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 26)                1066      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 27        \n",
            "=================================================================\n",
            "Total params: 1,653\n",
            "Trainable params: 1,653\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noLad0jzXlCB"
      },
      "source": [
        "# Compile the model\n",
        "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjeRP6O1XpTp",
        "outputId": "4baedfb9-871c-41e2-ffa7-cffec90d1b34"
      },
      "source": [
        "# Train the model\n",
        "fit_model = nn.fit(X_train,y_train,epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 3ms/step - loss: 14.4013 - accuracy: 0.5463\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 9.3377 - accuracy: 0.3568\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 7.3269 - accuracy: 0.4273\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.4466 - accuracy: 0.5066\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.1073 - accuracy: 0.3877\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.1113 - accuracy: 0.4670\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.0529 - accuracy: 0.4273\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.1474 - accuracy: 0.4626\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4478 - accuracy: 0.4890\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.9887 - accuracy: 0.5683\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.8808 - accuracy: 0.6123\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8382 - accuracy: 0.6344\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7394 - accuracy: 0.6432\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7641 - accuracy: 0.6123\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7150 - accuracy: 0.6828\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6164 - accuracy: 0.6784\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6863 - accuracy: 0.6696\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5870 - accuracy: 0.7093\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5290 - accuracy: 0.7401\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.7621\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7665\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7489\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5547 - accuracy: 0.7137\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4942 - accuracy: 0.7753\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5239 - accuracy: 0.7401\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6040 - accuracy: 0.6652\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.8146 - accuracy: 0.6300\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.8308 - accuracy: 0.6123\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4836 - accuracy: 0.7621\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4780 - accuracy: 0.8018\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5362 - accuracy: 0.7181\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7533\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.8018\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.7577\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7615 - accuracy: 0.6784\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6048 - accuracy: 0.7048\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5519 - accuracy: 0.7357\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6439 - accuracy: 0.6960\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5523 - accuracy: 0.7004\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6967 - accuracy: 0.6784\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5902 - accuracy: 0.7225\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5033 - accuracy: 0.7621\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5016 - accuracy: 0.7753\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7930\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7753\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5865 - accuracy: 0.7753\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5584 - accuracy: 0.7225\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.7577\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.8018\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7577\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.8062\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4013 - accuracy: 0.8282\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5994 - accuracy: 0.7225\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5593 - accuracy: 0.7048\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5442 - accuracy: 0.7445\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3961 - accuracy: 0.8326\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.7665\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.8106\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3904 - accuracy: 0.8282\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3987 - accuracy: 0.8326\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4002 - accuracy: 0.8150\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.8062\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.8238\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3961 - accuracy: 0.8282\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.8062\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.8194\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4033 - accuracy: 0.8106\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6661 - accuracy: 0.7048\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5794 - accuracy: 0.7093\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5997 - accuracy: 0.7093\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5562 - accuracy: 0.7930\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.8194\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3794 - accuracy: 0.8282\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3687 - accuracy: 0.8370\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.8150\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3768 - accuracy: 0.8370\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4010 - accuracy: 0.8062\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4054 - accuracy: 0.8194\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4042 - accuracy: 0.8150\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7841\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3910 - accuracy: 0.7930\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.8062\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3640 - accuracy: 0.8414\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7621\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.8282\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.7930\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5602 - accuracy: 0.7401\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3884 - accuracy: 0.8194\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3934 - accuracy: 0.8370\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4485 - accuracy: 0.8018\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.7489\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3729 - accuracy: 0.8326\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7753\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3769 - accuracy: 0.8062\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3487 - accuracy: 0.8546\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3635 - accuracy: 0.8414\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3479 - accuracy: 0.8458\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3856 - accuracy: 0.8106\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7489\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5546 - accuracy: 0.7357\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-b3RO5UFXxI6",
        "outputId": "d678ecc2-9c91-445f-cd23-04a19c230e55"
      },
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 - 0s - loss: 0.5268 - accuracy: 0.7368\n",
            "Loss: 0.5268447995185852, Accuracy: 0.7368420958518982\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uJp3zPrX13K"
      },
      "source": [
        "#** Compile, Train and Evaluate the Model Adding Another Hidden layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mS4ZmCbX58x",
        "outputId": "13589ac8-c571-4baa-d80a-1dd80fd9448a"
      },
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "number_input_features = len(X_train_scaled [0])\n",
        "hidden_nodes_layer1 =  70\n",
        "hidden_nodes_layer2 = 40\n",
        "hidden_nodes_layer3 = 30\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(\n",
        "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
        ")\n",
        "\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
        "\n",
        "# Third hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3,activation=\"relu\"))\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 70)                980       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 40)                2840      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 30)                1230      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 31        \n",
            "=================================================================\n",
            "Total params: 5,081\n",
            "Trainable params: 5,081\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9rDNJeeYCgA"
      },
      "source": [
        "# Compile the model\n",
        "nn.compile(loss=\"binary_crossentropy\",\n",
        "           optimizer=\"adamax\",\n",
        "           metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObYeLypmYGFJ",
        "outputId": "f13eaba0-7a09-418f-98ee-dc969cd05603"
      },
      "source": [
        "# Train the model\n",
        "fit_model = nn.fit(X_train_scaled,\n",
        "                   y_train,epochs=200)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7184 - accuracy: 0.5330\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6758 - accuracy: 0.6167\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6514 - accuracy: 0.6740\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6302 - accuracy: 0.7313\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6098 - accuracy: 0.7577\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5899 - accuracy: 0.7930\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5702 - accuracy: 0.8106\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5499 - accuracy: 0.8370\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5303 - accuracy: 0.8326\n",
            "Epoch 10/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.8370\n",
            "Epoch 11/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4975 - accuracy: 0.8414\n",
            "Epoch 12/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.8458\n",
            "Epoch 13/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.8458\n",
            "Epoch 14/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4531 - accuracy: 0.8502\n",
            "Epoch 15/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.8502\n",
            "Epoch 16/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.8414\n",
            "Epoch 17/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.8502\n",
            "Epoch 18/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.8502\n",
            "Epoch 19/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3995 - accuracy: 0.8502\n",
            "Epoch 20/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3912 - accuracy: 0.8502\n",
            "Epoch 21/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3844 - accuracy: 0.8546\n",
            "Epoch 22/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3769 - accuracy: 0.8546\n",
            "Epoch 23/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3695 - accuracy: 0.8546\n",
            "Epoch 24/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3629 - accuracy: 0.8546\n",
            "Epoch 25/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3566 - accuracy: 0.8546\n",
            "Epoch 26/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3508 - accuracy: 0.8546\n",
            "Epoch 27/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3458 - accuracy: 0.8590\n",
            "Epoch 28/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3407 - accuracy: 0.8590\n",
            "Epoch 29/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3364 - accuracy: 0.8590\n",
            "Epoch 30/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.8678\n",
            "Epoch 31/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8678\n",
            "Epoch 32/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3236 - accuracy: 0.8678\n",
            "Epoch 33/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3198 - accuracy: 0.8634\n",
            "Epoch 34/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3162 - accuracy: 0.8678\n",
            "Epoch 35/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3134 - accuracy: 0.8678\n",
            "Epoch 36/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.8678\n",
            "Epoch 37/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 0.8678\n",
            "Epoch 38/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3056 - accuracy: 0.8678\n",
            "Epoch 39/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3027 - accuracy: 0.8678\n",
            "Epoch 40/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3001 - accuracy: 0.8678\n",
            "Epoch 41/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2974 - accuracy: 0.8678\n",
            "Epoch 42/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2951 - accuracy: 0.8722\n",
            "Epoch 43/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2926 - accuracy: 0.8722\n",
            "Epoch 44/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2905 - accuracy: 0.8722\n",
            "Epoch 45/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2885 - accuracy: 0.8722\n",
            "Epoch 46/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2862 - accuracy: 0.8722\n",
            "Epoch 47/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2839 - accuracy: 0.8722\n",
            "Epoch 48/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2824 - accuracy: 0.8722\n",
            "Epoch 49/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2804 - accuracy: 0.8722\n",
            "Epoch 50/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2782 - accuracy: 0.8767\n",
            "Epoch 51/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2759 - accuracy: 0.8767\n",
            "Epoch 52/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2740 - accuracy: 0.8767\n",
            "Epoch 53/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2721 - accuracy: 0.8811\n",
            "Epoch 54/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2705 - accuracy: 0.8811\n",
            "Epoch 55/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2687 - accuracy: 0.8811\n",
            "Epoch 56/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2668 - accuracy: 0.8811\n",
            "Epoch 57/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2652 - accuracy: 0.8855\n",
            "Epoch 58/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2638 - accuracy: 0.8811\n",
            "Epoch 59/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2620 - accuracy: 0.8855\n",
            "Epoch 60/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2606 - accuracy: 0.8855\n",
            "Epoch 61/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2588 - accuracy: 0.8855\n",
            "Epoch 62/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2579 - accuracy: 0.8855\n",
            "Epoch 63/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2569 - accuracy: 0.8811\n",
            "Epoch 64/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2558 - accuracy: 0.8811\n",
            "Epoch 65/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2542 - accuracy: 0.8811\n",
            "Epoch 66/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2529 - accuracy: 0.8855\n",
            "Epoch 67/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2511 - accuracy: 0.8855\n",
            "Epoch 68/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2497 - accuracy: 0.8899\n",
            "Epoch 69/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2482 - accuracy: 0.8899\n",
            "Epoch 70/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.8943\n",
            "Epoch 71/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.8943\n",
            "Epoch 72/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2440 - accuracy: 0.8987\n",
            "Epoch 73/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2426 - accuracy: 0.8987\n",
            "Epoch 74/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2412 - accuracy: 0.8987\n",
            "Epoch 75/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2400 - accuracy: 0.8987\n",
            "Epoch 76/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2388 - accuracy: 0.8987\n",
            "Epoch 77/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2375 - accuracy: 0.8943\n",
            "Epoch 78/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2362 - accuracy: 0.8987\n",
            "Epoch 79/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2348 - accuracy: 0.9031\n",
            "Epoch 80/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2332 - accuracy: 0.8987\n",
            "Epoch 81/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2319 - accuracy: 0.8987\n",
            "Epoch 82/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2307 - accuracy: 0.9031\n",
            "Epoch 83/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2293 - accuracy: 0.9075\n",
            "Epoch 84/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2282 - accuracy: 0.9031\n",
            "Epoch 85/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2273 - accuracy: 0.9031\n",
            "Epoch 86/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2266 - accuracy: 0.9031\n",
            "Epoch 87/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2251 - accuracy: 0.9031\n",
            "Epoch 88/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2235 - accuracy: 0.9031\n",
            "Epoch 89/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2221 - accuracy: 0.9075\n",
            "Epoch 90/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2212 - accuracy: 0.9075\n",
            "Epoch 91/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2199 - accuracy: 0.9075\n",
            "Epoch 92/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2188 - accuracy: 0.9075\n",
            "Epoch 93/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2176 - accuracy: 0.9075\n",
            "Epoch 94/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2165 - accuracy: 0.9075\n",
            "Epoch 95/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2153 - accuracy: 0.9163\n",
            "Epoch 96/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2146 - accuracy: 0.9207\n",
            "Epoch 97/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2135 - accuracy: 0.9207\n",
            "Epoch 98/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2121 - accuracy: 0.9163\n",
            "Epoch 99/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2111 - accuracy: 0.9163\n",
            "Epoch 100/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2103 - accuracy: 0.9251\n",
            "Epoch 101/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2090 - accuracy: 0.9207\n",
            "Epoch 102/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2078 - accuracy: 0.9207\n",
            "Epoch 103/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2069 - accuracy: 0.9207\n",
            "Epoch 104/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2058 - accuracy: 0.9207\n",
            "Epoch 105/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2047 - accuracy: 0.9207\n",
            "Epoch 106/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2037 - accuracy: 0.9251\n",
            "Epoch 107/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2026 - accuracy: 0.9251\n",
            "Epoch 108/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2012 - accuracy: 0.9251\n",
            "Epoch 109/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2005 - accuracy: 0.9295\n",
            "Epoch 110/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1995 - accuracy: 0.9295\n",
            "Epoch 111/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1986 - accuracy: 0.9295\n",
            "Epoch 112/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1975 - accuracy: 0.9295\n",
            "Epoch 113/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1963 - accuracy: 0.9295\n",
            "Epoch 114/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1953 - accuracy: 0.9295\n",
            "Epoch 115/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1943 - accuracy: 0.9251\n",
            "Epoch 116/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1935 - accuracy: 0.9251\n",
            "Epoch 117/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1925 - accuracy: 0.9251\n",
            "Epoch 118/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1914 - accuracy: 0.9295\n",
            "Epoch 119/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1904 - accuracy: 0.9295\n",
            "Epoch 120/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1895 - accuracy: 0.9295\n",
            "Epoch 121/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1883 - accuracy: 0.9295\n",
            "Epoch 122/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1874 - accuracy: 0.9295\n",
            "Epoch 123/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1862 - accuracy: 0.9295\n",
            "Epoch 124/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1853 - accuracy: 0.9295\n",
            "Epoch 125/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1845 - accuracy: 0.9295\n",
            "Epoch 126/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1831 - accuracy: 0.9295\n",
            "Epoch 127/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1822 - accuracy: 0.9295\n",
            "Epoch 128/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1811 - accuracy: 0.9295\n",
            "Epoch 129/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1803 - accuracy: 0.9251\n",
            "Epoch 130/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1793 - accuracy: 0.9295\n",
            "Epoch 131/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1777 - accuracy: 0.9295\n",
            "Epoch 132/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1773 - accuracy: 0.9339\n",
            "Epoch 133/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1761 - accuracy: 0.9339\n",
            "Epoch 134/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1750 - accuracy: 0.9339\n",
            "Epoch 135/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1741 - accuracy: 0.9251\n",
            "Epoch 136/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1730 - accuracy: 0.9251\n",
            "Epoch 137/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1717 - accuracy: 0.9251\n",
            "Epoch 138/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1706 - accuracy: 0.9251\n",
            "Epoch 139/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1696 - accuracy: 0.9295\n",
            "Epoch 140/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1688 - accuracy: 0.9383\n",
            "Epoch 141/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1677 - accuracy: 0.9339\n",
            "Epoch 142/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1667 - accuracy: 0.9251\n",
            "Epoch 143/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1654 - accuracy: 0.9295\n",
            "Epoch 144/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1645 - accuracy: 0.9339\n",
            "Epoch 145/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1636 - accuracy: 0.9339\n",
            "Epoch 146/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1626 - accuracy: 0.9339\n",
            "Epoch 147/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1615 - accuracy: 0.9383\n",
            "Epoch 148/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1607 - accuracy: 0.9427\n",
            "Epoch 149/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1593 - accuracy: 0.9427\n",
            "Epoch 150/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1584 - accuracy: 0.9427\n",
            "Epoch 151/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1574 - accuracy: 0.9427\n",
            "Epoch 152/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1560 - accuracy: 0.9427\n",
            "Epoch 153/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1551 - accuracy: 0.9471\n",
            "Epoch 154/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1538 - accuracy: 0.9471\n",
            "Epoch 155/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1532 - accuracy: 0.9471\n",
            "Epoch 156/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1518 - accuracy: 0.9471\n",
            "Epoch 157/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1505 - accuracy: 0.9471\n",
            "Epoch 158/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1499 - accuracy: 0.9471\n",
            "Epoch 159/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1487 - accuracy: 0.9471\n",
            "Epoch 160/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1476 - accuracy: 0.9515\n",
            "Epoch 161/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1466 - accuracy: 0.9515\n",
            "Epoch 162/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1455 - accuracy: 0.9515\n",
            "Epoch 163/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1445 - accuracy: 0.9515\n",
            "Epoch 164/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1435 - accuracy: 0.9559\n",
            "Epoch 165/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1425 - accuracy: 0.9559\n",
            "Epoch 166/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1415 - accuracy: 0.9559\n",
            "Epoch 167/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1404 - accuracy: 0.9604\n",
            "Epoch 168/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1394 - accuracy: 0.9604\n",
            "Epoch 169/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1382 - accuracy: 0.9604\n",
            "Epoch 170/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1372 - accuracy: 0.9604\n",
            "Epoch 171/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1365 - accuracy: 0.9559\n",
            "Epoch 172/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1357 - accuracy: 0.9604\n",
            "Epoch 173/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1347 - accuracy: 0.9604\n",
            "Epoch 174/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1334 - accuracy: 0.9604\n",
            "Epoch 175/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1326 - accuracy: 0.9604\n",
            "Epoch 176/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1316 - accuracy: 0.9604\n",
            "Epoch 177/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1308 - accuracy: 0.9604\n",
            "Epoch 178/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1299 - accuracy: 0.9604\n",
            "Epoch 179/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1289 - accuracy: 0.9604\n",
            "Epoch 180/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1280 - accuracy: 0.9604\n",
            "Epoch 181/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1269 - accuracy: 0.9604\n",
            "Epoch 182/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1260 - accuracy: 0.9604\n",
            "Epoch 183/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1250 - accuracy: 0.9604\n",
            "Epoch 184/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1240 - accuracy: 0.9604\n",
            "Epoch 185/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1233 - accuracy: 0.9604\n",
            "Epoch 186/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1220 - accuracy: 0.9604\n",
            "Epoch 187/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1212 - accuracy: 0.9604\n",
            "Epoch 188/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1203 - accuracy: 0.9604\n",
            "Epoch 189/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1193 - accuracy: 0.9604\n",
            "Epoch 190/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1185 - accuracy: 0.9604\n",
            "Epoch 191/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1175 - accuracy: 0.9604\n",
            "Epoch 192/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9604\n",
            "Epoch 193/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1157 - accuracy: 0.9604\n",
            "Epoch 194/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1150 - accuracy: 0.9604\n",
            "Epoch 195/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1140 - accuracy: 0.9604\n",
            "Epoch 196/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1131 - accuracy: 0.9648\n",
            "Epoch 197/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1122 - accuracy: 0.9648\n",
            "Epoch 198/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1114 - accuracy: 0.9648\n",
            "Epoch 199/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1104 - accuracy: 0.9648\n",
            "Epoch 200/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1095 - accuracy: 0.9648\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "WGkUIIixYKfi",
        "outputId": "a69cd6e3-1a70-4ea2-ba2a-66b3c4cad3c3"
      },
      "source": [
        "# Create a DataFrame containing training history\n",
        "history_df = pd.DataFrame(fit_model.history, index=range(1,len(fit_model.history[\"loss\"])+1))\n",
        "\n",
        "# Plot the loss\n",
        "history_df.plot(y=\"loss\")\n",
        "#TO READ THE LOSS GRAPH :https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fdfaabbd390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "jJngvuAOYMvy",
        "outputId": "455616f3-fe92-4241-d995-7fd107fdcb5d"
      },
      "source": [
        "# Plot the accuracy\n",
        "history_df.plot(y=\"accuracy\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fdfaaaa76d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5q_jvgKdYUni",
        "outputId": "2bd6f1d1-2bff-4981-adc4-35670cc6f090"
      },
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 - 0s - loss: 0.4720 - accuracy: 0.8289\n",
            "Loss: 0.47200432419776917, Accuracy: 0.8289473652839661\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}